# DataCon25_Alzheimer
**1. Выбор мишени**
В данной задаче мы решили сфокусироваться на Adenosine receptor a2a, GTPase белком, нативным лигандом которого является аденозин. Известно, что связывание данного рецептора с его антагонистами (например, кофеином) приводит к снижению нейровоспаления. Поскольку болезнь Альцгеймера считается полигенным заболеванием, вследствие чего становится невозможным обнаружить одну мишень для воздействия, мы решили сфокусироваться на снижении негативного воздействия тау белка и амилоид-бета белка на нейроны мозга, а точнее на снижении нейровоспаления, приводящего к гибели нейронов, вместо продукта конкретного гена, ответственного за появление данных белков.
https://pubmed.ncbi.nlm.nih.gov/35870032/
https://pubmed.ncbi.nlm.nih.gov/38717958/
https://pubmed.ncbi.nlm.nih.gov/38964748/
**2. Предсказание активности**
Для данного человеческого рецептора было доступно 10924 записи об известных лигандах в базе Binding db. Далее мы произвели sanity check записей и нашли дескрипторы лигандов.
Значения IC50 и Ki мы считали приблизительно равными и преобразовали их в pValue (то есть взяли -log10(Value)), измеряемому в nM. 
Далее мы перешли к подготовке датасета для обучения моделей ML. В результате первичной обработки датасета (отбор валидных строк) количество записей уменьшилось до 7115. В ходе подготовки датасета также были удалены признаки, значения которых равны 0 для более, чем 90% молекул. Также мы проверили колонки на скоррелированность (коэффициент пирсона > 0.7) и оставили только по одной из скоррелированных колонок: количество колонок с дескрипторами в итоге сократилось до 77 (исходно 217 дескрипторов). После проверки на наличие Nan в строках в значимых столбцах количество строк сократилось до 7068.

Далее мы перешли к обучению моделей: нами были использованы Random Forest, Gradient Boosting и CatBoost. Другие модели классического ML мы не стали использовать, потому что наш датасет обладает большим количеством признаков и сложными зависимостями, которые более простые модели чаще всего уловить не могут. Нейросети также не были использованы по причине того, что на табличных данных хорошо работают и методы градиентного бустинга, ну и потому что мы не успели их попробовать((

В качестве X использовали только оставшиеся дескрипторы, в качестве Y предсказывали pIC50 в nM.
X разбили на тренировочную, валидационную и тестовую выборки. Проводили стандартизацию признаков. Поскольку признаков очень много, использовали PCA для понижения размерности. 
Наиболее оптимальные гиперпараметры для каждой из моделей подбирали с помощью Optuna. Для проверки стабильности результатов проводили кросс-валидацию с наиболее оптимальными гиперпараметрами.
r2 scores на тестовой выборке: CatBoostRegressor=0.6229, RandomForestRegressor=0.569, GradientBoosting=0.57. Для дальнейшего предсказания активности сгенерированных молекул использовали CatBoostRegressor.

**3. Генерация молекул**
Для генерации молекул использовалась модель DrugGPT, поскольку для данной модели были показана способность проводить оптимизацию структур лигандов и большая доля выводимых ею молекул имеет корректный smiles (). Всего было сгенерировано 105 лигандов, из которых один лиганд имел неверный smiles, для 104 лигандов были рассчитаны молекулярные свойства: QED, SA Score, Toxicophore, Lipinski и Topological Polar Surface Area для оценки проницаемости через гематоэнцефалический барьер.
Было найдено 13 молекул, обладающих оптимальными свойствами. В среднем tanimoto similarity сгенерированных молекул друг с другом составило 0.3446, что означает, что молекулы несильно похожи друг на друга.

